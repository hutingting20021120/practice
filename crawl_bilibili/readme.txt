本次作业选用bilibili纪录片频道最高评分榜单作为爬虫网页，爬取了评分前100名纪录片的片名、评分、热度、主题、年份、简介以及BV码。代码总体逻辑是：用手工配合登录的方法获得cookies—使用cookies进入登录状态—从首页出发经过两次点击进入纪录片最高评分子网页—批量储存每一页纪录片的url链接—遍历每个链接详情页储存信息—通过更改url的page={}实现翻页—循环五次（每页20项，共计100项）。获得cookies后，在final.py中运行，从主页进入纪录片最高评分子网页的两次点击通过按回车的方式手动等待页面加载完成，之后不需要任何操作，可得到csv结果文件。

作业过程中遇到的困难有：
1、一开始想要避开从首页进入子网页的两次点击，尝试直接在子网页登录，但无法成功，只有首页能使用cookies登录。
2、在进入“纪录片”频道后，尝试进入“最高评分”页面时，一直报错找不到相应的元素。尝试更换xpath、cssselector、id，更改chromedriver版本等各种方法都无法解决。兜了很大的圈子，经过各种搜索后，终于发现需要切换为新的标签页，否则就默认在第一个标签页内查找，自然是找不到的。这里花费了最长的时间。反思：课上使用的案例网页是在当前标签页加载子网页，不用切换窗口，虽然老师提到过切换窗口的功能，但我没有和查找页面元素联系起来，导致这里忽略了不同网页打开新标签页的方式不同。
3、循环遍历过程中又出现了等待时间过短导致元素还未加载完整、元素已更新导致无法操作等问题，借助工具优化代码后解决。
4、在纪录片详情页查找信息时，原本全部采用xpath定位，但在第四个纪录片页面后有的元素就找不到了，推测是后期进行过调整导致网页编写不统一。于是采用cssselector和xpath混合定位的方式，可以适配所有纪录片页面。

总的来说，感觉python网络爬虫实际应用比课堂讲授更加复杂琐碎，每个网页都不尽相同，因此没有统一适配的模板，需要灵活调整策略。
